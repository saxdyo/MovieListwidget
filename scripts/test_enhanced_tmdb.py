#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºç‰ˆTMDBæ•°æ®çˆ¬å–åŠŸèƒ½
"""

import os
import json
import sys
from datetime import datetime, timezone, timedelta

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_data_structure():
    """æµ‹è¯•æ•°æ®ç»“æ„"""
    print("=== æµ‹è¯•æ•°æ®ç»“æ„ ===")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_file = os.path.join(os.getcwd(), "data", "TMDB_Trending.json")
    if not os.path.exists(data_file):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("âœ… æ•°æ®æ–‡ä»¶è¯»å–æˆåŠŸ")
        
        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        required_keys = ["last_updated", "today_global", "week_global_all", "popular_movies"]
        for key in required_keys:
            if key not in data:
                print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")
                return False
        
        print("âœ… åŸºæœ¬æ•°æ®ç»“æ„æ­£ç¡®")
        
        # æ£€æŸ¥å…ƒæ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰
        metadata = data.get("metadata", {})
        if metadata:
            print(f"âœ… å…ƒæ•°æ®ç‰ˆæœ¬: {metadata.get('version', 'unknown')}")
            print(f"âœ… åŠŸèƒ½ç‰¹æ€§: {metadata.get('features', [])}")
            print(f"âœ… æ€»é¡¹ç›®æ•°: {metadata.get('total_items', 0)}")
            print(f"âœ… Logoæ•°é‡: {metadata.get('logos_count', 0)}")
            print(f"âœ… èƒŒæ™¯å›¾æ•°é‡: {metadata.get('backdrops_count', 0)}")
        else:
            # æ£€æŸ¥æ—§æ ¼å¼çš„ç‰ˆæœ¬ä¿¡æ¯
            version = data.get("version", "unknown")
            print(f"âœ… æ•°æ®ç‰ˆæœ¬: {version}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def test_item_structure():
    """æµ‹è¯•å•ä¸ªé¡¹ç›®çš„æ•°æ®ç»“æ„"""
    print("\n=== æµ‹è¯•é¡¹ç›®æ•°æ®ç»“æ„ ===")
    
    data_file = os.path.join(os.getcwd(), "data", "TMDB_Trending.json")
    if not os.path.exists(data_file):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥æ‰€æœ‰æ•°æ®åˆ—è¡¨
        all_items = []
        all_items.extend(data.get("today_global", []))
        all_items.extend(data.get("week_global_all", []))
        all_items.extend(data.get("popular_movies", []))
        
        if not all_items:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®æ•°æ®")
            return True
        
        print(f"âœ… æ‰¾åˆ° {len(all_items)} ä¸ªé¡¹ç›®")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªé¡¹ç›®çš„ç»“æ„
        first_item = all_items[0]
        
        # æ–°æ ¼å¼çš„å¿…éœ€å­—æ®µ
        new_format_keys = ["id", "title", "type", "genreTitle", "rating", "poster_url"]
        # æ—§æ ¼å¼çš„å¿…éœ€å­—æ®µ
        old_format_keys = ["id", "title", "name", "media_type", "vote_average", "poster_path"]
        
        # åˆ¤æ–­æ˜¯å“ªç§æ ¼å¼
        is_new_format = "type" in first_item and "genreTitle" in first_item
        is_old_format = "media_type" in first_item and "poster_path" in first_item
        
        if is_new_format:
            print("ğŸ“‹ æ£€æµ‹åˆ°æ–°æ ¼å¼æ•°æ®")
            required_keys = new_format_keys
            enhanced_keys = ["title_backdrop", "logo_url", "original_poster"]
        elif is_old_format:
            print("ğŸ“‹ æ£€æµ‹åˆ°æ—§æ ¼å¼æ•°æ®")
            required_keys = old_format_keys
            enhanced_keys = []
        else:
            print("âš ï¸ æœªçŸ¥æ•°æ®æ ¼å¼")
            return True
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        missing_keys = []
        for key in required_keys:
            if key not in first_item:
                missing_keys.append(key)
        
        if missing_keys:
            print(f"âš ï¸ ç¼ºå°‘å­—æ®µ: {missing_keys}")
        else:
            print("âœ… åŸºæœ¬é¡¹ç›®ç»“æ„æ­£ç¡®")
        
        # æ£€æŸ¥å¢å¼ºå­—æ®µï¼ˆä»…æ–°æ ¼å¼ï¼‰
        if is_new_format and enhanced_keys:
            enhanced_count = 0
            for key in enhanced_keys:
                if key in first_item and first_item[key]:
                    enhanced_count += 1
            
            print(f"âœ… å¢å¼ºå­—æ®µè¦†ç›–ç‡: {enhanced_count}/{len(enhanced_keys)}")
        
        # æ˜¾ç¤ºç¤ºä¾‹é¡¹ç›®
        print("\nğŸ“‹ ç¤ºä¾‹é¡¹ç›®:")
        if is_new_format:
            print(f"   æ ‡é¢˜: {first_item.get('title')}")
            print(f"   ç±»å‹: {first_item.get('type')}")
            print(f"   è¯„åˆ†: {first_item.get('rating')}")
            print(f"   æµ·æŠ¥: {'âœ…' if first_item.get('poster_url') else 'âŒ'}")
            print(f"   èƒŒæ™¯å›¾: {'âœ…' if first_item.get('title_backdrop') else 'âŒ'}")
            print(f"   Logo: {'âœ…' if first_item.get('logo_url') else 'âŒ'}")
        else:
            title = first_item.get('title') or first_item.get('name')
            print(f"   æ ‡é¢˜: {title}")
            print(f"   ç±»å‹: {first_item.get('media_type')}")
            print(f"   è¯„åˆ†: {first_item.get('vote_average')}")
            print(f"   æµ·æŠ¥è·¯å¾„: {'âœ…' if first_item.get('poster_path') else 'âŒ'}")
            print(f"   èƒŒæ™¯è·¯å¾„: {'âœ…' if first_item.get('backdrop_path') else 'âŒ'}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•é¡¹ç›®ç»“æ„å¤±è´¥: {e}")
        return False

def test_image_urls():
    """æµ‹è¯•å›¾ç‰‡URLçš„æœ‰æ•ˆæ€§"""
    print("\n=== æµ‹è¯•å›¾ç‰‡URL ===")
    
    data_file = os.path.join(os.getcwd(), "data", "TMDB_Trending.json")
    if not os.path.exists(data_file):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        all_items = []
        all_items.extend(data.get("today_global", []))
        all_items.extend(data.get("week_global_all", []))
        all_items.extend(data.get("popular_movies", []))
        
        if not all_items:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®æ•°æ®")
            return True
        
        # åˆ¤æ–­æ•°æ®æ ¼å¼
        first_item = all_items[0]
        is_new_format = "poster_url" in first_item
        is_old_format = "poster_path" in first_item
        
        if is_new_format:
            # æ–°æ ¼å¼ç»Ÿè®¡
            poster_count = sum(1 for item in all_items if item.get("poster_url"))
            backdrop_count = sum(1 for item in all_items if item.get("title_backdrop"))
            logo_count = sum(1 for item in all_items if item.get("logo_url"))
            
            print(f"âœ… æµ·æŠ¥URL: {poster_count}/{len(all_items)}")
            print(f"âœ… èƒŒæ™¯å›¾URL: {backdrop_count}/{len(all_items)}")
            print(f"âœ… Logo URL: {logo_count}/{len(all_items)}")
            
            # æ£€æŸ¥URLæ ¼å¼
            sample_urls = []
            for item in all_items[:3]:
                if item.get("poster_url"):
                    sample_urls.append(item["poster_url"])
                if item.get("title_backdrop"):
                    sample_urls.append(item["title_backdrop"])
                if item.get("logo_url"):
                    sample_urls.append(item["logo_url"])
            
            for url in sample_urls:
                if url.startswith("https://image.tmdb.org/t/p/"):
                    print(f"âœ… URLæ ¼å¼æ­£ç¡®: {url[:50]}...")
                else:
                    print(f"âŒ URLæ ¼å¼é”™è¯¯: {url}")
                    
        elif is_old_format:
            # æ—§æ ¼å¼ç»Ÿè®¡
            poster_count = sum(1 for item in all_items if item.get("poster_path"))
            backdrop_count = sum(1 for item in all_items if item.get("backdrop_path"))
            
            print(f"âœ… æµ·æŠ¥è·¯å¾„: {poster_count}/{len(all_items)}")
            print(f"âœ… èƒŒæ™¯è·¯å¾„: {backdrop_count}/{len(all_items)}")
            print("â„¹ï¸ æ—§æ ¼å¼æ•°æ®ï¼Œéœ€è¦è¿è¡Œå¢å¼ºè„šæœ¬ç”Ÿæˆå®Œæ•´URL")
            
            # æ£€æŸ¥è·¯å¾„æ ¼å¼
            sample_paths = []
            for item in all_items[:3]:
                if item.get("poster_path"):
                    sample_paths.append(item["poster_path"])
                if item.get("backdrop_path"):
                    sample_paths.append(item["backdrop_path"])
            
            for path in sample_paths:
                if path.startswith("/"):
                    print(f"âœ… è·¯å¾„æ ¼å¼æ­£ç¡®: {path}")
                else:
                    print(f"âŒ è·¯å¾„æ ¼å¼é”™è¯¯: {path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å›¾ç‰‡URLå¤±è´¥: {e}")
        return False

def test_timestamp():
    """æµ‹è¯•æ—¶é—´æˆ³æ ¼å¼"""
    print("\n=== æµ‹è¯•æ—¶é—´æˆ³ ===")
    
    data_file = os.path.join(os.getcwd(), "data", "TMDB_Trending.json")
    if not os.path.exists(data_file):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        last_updated = data.get("last_updated")
        if not last_updated:
            print("âŒ ç¼ºå°‘æ—¶é—´æˆ³")
            return False
        
        # å°è¯•è§£æä¸åŒçš„æ—¶é—´æˆ³æ ¼å¼
        try:
            # å°è¯•æ–°æ ¼å¼: "2024-01-01 12:00:00"
            dt = datetime.strptime(last_updated, "%Y-%m-%d %H:%M:%S")
            print(f"âœ… æ—¶é—´æˆ³æ ¼å¼æ­£ç¡® (æ–°æ ¼å¼): {last_updated}")
        except ValueError:
            try:
                # å°è¯•ISOæ ¼å¼: "2025-01-20T10:30:00Z"
                dt = datetime.fromisoformat(last_updated.replace('Z', '+00:00'))
                print(f"âœ… æ—¶é—´æˆ³æ ¼å¼æ­£ç¡® (ISOæ ¼å¼): {last_updated}")
            except ValueError:
                print(f"âŒ æ—¶é—´æˆ³æ ¼å¼é”™è¯¯: {last_updated}")
                return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€è¿‘æ—¶é—´
        beijing_timezone = timezone(timedelta(hours=8))
        beijing_now = datetime.now(beijing_timezone)
        
        # å¦‚æœæ—¶é—´æˆ³æœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        if dt.tzinfo:
            dt = dt.astimezone(beijing_timezone)
        else:
            # å‡è®¾ä¸ºUTCæ—¶é—´
            dt = dt.replace(tzinfo=timezone.utc).astimezone(beijing_timezone)
        
        time_diff = abs((beijing_now - dt).total_seconds())
        
        if time_diff < 3600:  # 1å°æ—¶å†…
            print("âœ… æ—¶é—´æˆ³ä¸ºæœ€è¿‘æ—¶é—´")
        else:
            print(f"âš ï¸ æ—¶é—´æˆ³å¯èƒ½è¾ƒæ—§ï¼Œç›¸å·® {time_diff/3600:.1f} å°æ—¶")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ—¶é—´æˆ³å¤±è´¥: {e}")
        return False

def test_data_quality():
    """æµ‹è¯•æ•°æ®è´¨é‡"""
    print("\n=== æµ‹è¯•æ•°æ®è´¨é‡ ===")
    
    data_file = os.path.join(os.getcwd(), "data", "TMDB_Trending.json")
    if not os.path.exists(data_file):
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        all_items = []
        all_items.extend(data.get("today_global", []))
        all_items.extend(data.get("week_global_all", []))
        all_items.extend(data.get("popular_movies", []))
        
        if not all_items:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®æ•°æ®")
            return True
        
        # æ•°æ®è´¨é‡ç»Ÿè®¡
        total_items = len(all_items)
        items_with_title = sum(1 for item in all_items if item.get("title") or item.get("name"))
        items_with_overview = sum(1 for item in all_items if item.get("overview"))
        items_with_rating = sum(1 for item in all_items if item.get("vote_average") or item.get("rating"))
        
        print(f"âœ… æ€»é¡¹ç›®æ•°: {total_items}")
        print(f"âœ… æœ‰æ ‡é¢˜çš„é¡¹ç›®: {items_with_title}/{total_items}")
        print(f"âœ… æœ‰ç®€ä»‹çš„é¡¹ç›®: {items_with_overview}/{total_items}")
        print(f"âœ… æœ‰è¯„åˆ†çš„é¡¹ç›®: {items_with_rating}/{total_items}")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        completeness = (items_with_title + items_with_overview + items_with_rating) / (total_items * 3) * 100
        print(f"âœ… æ•°æ®å®Œæ•´æ€§: {completeness:.1f}%")
        
        if completeness >= 80:
            print("âœ… æ•°æ®è´¨é‡è‰¯å¥½")
        elif completeness >= 60:
            print("âš ï¸ æ•°æ®è´¨é‡ä¸€èˆ¬")
        else:
            print("âŒ æ•°æ®è´¨é‡è¾ƒå·®")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ•°æ®è´¨é‡å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºç‰ˆTMDBæ•°æ®çˆ¬å–åŠŸèƒ½")
    print("=" * 50)
    
    tests = [
        test_data_structure,
        test_item_structure,
        test_image_urls,
        test_timestamp,
        test_data_quality
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    elif passed >= total * 0.8:
        print("âœ… å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œæ•°æ®å¯ç”¨")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®è¿è¡Œå¢å¼ºè„šæœ¬æ›´æ–°æ•°æ®")
        return 1

if __name__ == "__main__":
    exit(main())